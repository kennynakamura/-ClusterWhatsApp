# -*- coding: utf-8 -*-
"""WhatsAppCluster.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZEipaX1o40bQ51G8kyOwPYp1R71RyOZL
"""

import re
import os
import plotly
import numpy as np
import pandas as pd
from os import path
from pathlib import Path
import plotly.express as px
from pandas import DataFrame
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
import string
from nltk import word_tokenize
from nltk.corpus import stopwords
nltk.download('punkt')
nltk.download('stopwords')

def starts_with_date_time(s):
    pattern = '^([0-9]+)(\/)([0-9]+)(\/)([0-9]+)[ ]([0-9]+):([0-9]+)[ ]-'
    result = re.match(pattern, s)
    if result:
        return True
    return False

def find_author(s):
  s=s.split(":")
  if len(s) > 1:
    return True
  else:
    return False

def split_count(text):
    emoji_list = []
    data = regex.findall(r'\X', text)
    for word in data:
        if any(char in emoji.UNICODE_EMOJI for char in word):
            emoji_list.append(word)
    return emoji_list

def get_data_point(line):
    split_l = line.split(' - ')
    date_time = split_l[0]
    date, time = date_time.split(' ')
    message = ' '.join(split_l[1:])
    split_msg = message.split(': ')
    author = split_msg[0]
    message = ' '.join(split_msg[1:])
    return date, time, author, message

def tiraroculto(dataframe):
  dataframe = dataframe.drop(df[df.message =='<Arquivo de mídia oculto>'].index)
  return dataframe

def Textos(path):
    for filename in os.listdir(path):
        if filename.endswith('.txt'):
           with open(os.path.join(path, filename)) as f:
                nome = Path(filename).name
                titulo.append(nome)
                linha = f.read()
                lista.append(linha)
    return

def Grafico(a,b):
  K = range(a,b)
  for k in K:
      km = KMeans(n_clusters=k, max_iter=200, n_init=10)
      km = km.fit(X)
      Sum_of_squared_distances.append(km.inertia_)
  plt.plot(K, Sum_of_squared_distances, 'bx-')
  plt.xlabel('k')
  plt.ylabel('Sum_of_squared_distances')
  plt.title('Elbow Method For Optimal k')
  plt.show()
  return

k = NUMERO DE CLUSTERS



ll = []
#Colocar o endereço da pasta "data"
path = "/content/data/"
for filename in os.listdir(path):
   parsed = []
   nome = Path(path + filename).name
   if nome.endswith(".txt"):
     with open(path + nome, encoding="utf-8") as fp:
       fp.readline()
       name = Path(nome).stem
       msg_buffer = []
       date, time, author = None, None, None
       while True:
          line = fp.readline()
          if not line:
              break
          line = line.strip()
          if starts_with_date_time(line):
              if len(msg_buffer) > 0:
                  parsed.append([date, time, author, ' '.join(msg_buffer), name])
              msg_buffer.clear()
              date, time, author, message = get_data_point(line)
              msg_buffer.append(message)
          else:
              msg_buffer.append(line)
     nome = nome.replace(" ","")
     df = pd.DataFrame(parsed, columns=['date', 'time', 'author', 'message', 'name'])
     df["date"] = pd.to_datetime(df["date"])
     df = tiraroculto(df)
     df = df['message']
     ll.append((str(df)))

lista = []
titulo = []
Sum_of_squared_distances = []
#Endereço para acessar a pasta "data". obs: sem o '/'
Textos('/content/data')
vectorizer = TfidfVectorizer(stop_words={'portuguese'})
X = vectorizer.fit_transform(ll)
Grafico(2,5)

true_k = k
model = KMeans(n_clusters=true_k, init='k-means++', max_iter=200, n_init=10)
model.fit(X)
labels=model.labels_
tabela=pd.DataFrame(list(zip(titulo,labels)),columns=['Título','cluster'])
print(tabela.sort_values(by=['cluster']))